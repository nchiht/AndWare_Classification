{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKU5Rn9etS7_"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/intel/openfl.git\n",
        "!pip install -r requirements_workflow_interface.txt\n",
        "\n",
        "# Uncomment this if running in Google Colab\n",
        "!pip install -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt\n",
        "import os\n",
        "os.environ[\"USERNAME\"] = \"colab\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmO1l6fj3qLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9193d5-fc39-4f5d-8a43-76b6086f518f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Projeto-IA-22-23-Malware-Android'...\n",
            "remote: Enumerating objects: 227, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 227 (delta 26), reused 14 (delta 12), pack-reused 188\u001b[K\n",
            "Receiving objects: 100% (227/227), 130.71 MiB | 37.49 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.1\n"
          ]
        }
      ],
      "source": [
        "!git clone 'https://github.com/Luis-P-Duarte/Projeto-IA-22-23-Malware-Android.git'\n",
        "!pip install rarfile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRK5OhRX3xn7"
      },
      "outputs": [],
      "source": [
        "import rarfile\n",
        "\n",
        "# Đường dẫn đến tệp .rar trên Google Drive\n",
        "rar_path = '/content/Projeto-IA-22-23-Malware-Android/Images/64x64.rar'\n",
        "\n",
        "# Giải nén tệp .rar\n",
        "with rarfile.RarFile(rar_path, 'r') as rf:\n",
        "    rf.extractall('/content/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EJj9UeT4Ne5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# n_epochs = 3\n",
        "batch_size_train = 32\n",
        "batch_size_test = 32\n",
        "log_interval = 2\n",
        "\n",
        "\n",
        "# random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "# torch.manual_seed(random_seed)\n",
        "\n",
        "# Custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.dataset = ImageFolder(root_dir, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[idx]\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "datasetfull = CustomDataset(root_dir='/content/data/64x64', transform=transform)\n",
        "\n",
        "# Tính kích thước cho phần dữ liệu bạn muốn giữ lại (10%)\n",
        "desired_size = int(0.2 * len(datasetfull))\n",
        "\n",
        "# Tính kích thước cho phần còn lại của dữ liệu\n",
        "remaining_size = len(datasetfull) - desired_size\n",
        "\n",
        "# Tạo phần dữ liệu bạn muốn giữ lại\n",
        "dataset, _ = random_split(datasetfull, [desired_size, remaining_size])\n",
        "\n",
        "# Split dataset into train and validation sets\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idyg_rzH6bDa"
      },
      "outputs": [],
      "source": [
        "# Define your model\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=1)\n",
        "        self.pool = nn.MaxPool2d(2, stride=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * 59 * 59, 500)\n",
        "        self.fc2 = nn.Linear(500, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def inference(network, test_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        network = network.to('cuda:0')\n",
        "    network.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total_samples_val = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "          if torch.cuda.is_available():\n",
        "                inputs = inputs.to('cuda:0')\n",
        "                labels = labels.to('cuda:0')\n",
        "          outputs = network(inputs)\n",
        "          test_loss += F.nll_loss(outputs, labels).item()\n",
        "          _, predicted_val = torch.max(outputs.data, 1)\n",
        "          total_samples_val += labels.size(0)\n",
        "          correct += (predicted_val == labels).sum().item()\n",
        "\n",
        "    test_loss /= total_samples_val\n",
        "    accuracy = correct / total_samples_val\n",
        "\n",
        "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, total_samples_val, 100. * accuracy))\n",
        "\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShvYJAAVz9xg"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
        "from openfl.experimental.runtime import LocalRuntime\n",
        "from openfl.experimental.placement import aggregator, collaborator\n",
        "\n",
        "\n",
        "def FedAvg(models, weights=None):\n",
        "    models = [model.to('cpu') for model in models]\n",
        "    new_model = models[0]\n",
        "    state_dicts = [model.state_dict() for model in models]\n",
        "    state_dict = new_model.state_dict()\n",
        "    for key in models[1].state_dict():\n",
        "        state_dict[key] = torch.from_numpy(np.average([state[key].numpy() for state in state_dicts],\n",
        "                                                      axis=0,\n",
        "                                                      weights=weights))\n",
        "    new_model.load_state_dict(state_dict)\n",
        "    return new_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fROWYmrJ4g7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8a84dc-4e5a-4829-ff90-821a4841c217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregator step \"start\" registered\n",
            "Collaborator step \"aggregated_model_validation\" registered\n",
            "Collaborator step \"train\" registered\n",
            "Collaborator step \"local_model_validation\" registered\n",
            "Aggregator step \"join\" registered\n",
            "Aggregator step \"end\" registered\n"
          ]
        }
      ],
      "source": [
        "class FederatedFlow(FLSpec):\n",
        "\n",
        "    def __init__(self, model = None, optimizer = None, criterion = None, rounds=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        if model is not None:\n",
        "            self.model = model\n",
        "            self.optimizer = optimizer\n",
        "            self.criterion = criterion\n",
        "        else:\n",
        "            self.model = MyModel()\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "        self.rounds = rounds\n",
        "\n",
        "    @aggregator\n",
        "    def start(self):\n",
        "        print(f'Performing initialization for model')\n",
        "        self.collaborators = self.runtime.collaborators\n",
        "        self.private = 10\n",
        "        self.current_round = 0\n",
        "        self.next(self.aggregated_model_validation,foreach='collaborators',exclude=['private'])\n",
        "\n",
        "    @collaborator\n",
        "    def aggregated_model_validation(self):\n",
        "        print(f'Performing aggregated model validation for collaborator {self.input}')\n",
        "        self.agg_validation_score = inference(self.model,self.test_loader)\n",
        "        print(f'{self.input} value of {self.agg_validation_score}')\n",
        "        self.next(self.train)\n",
        "\n",
        "    @collaborator\n",
        "    def train(self):\n",
        "      if torch.cuda.is_available():\n",
        "        self.model = self.model.to('cuda:0')\n",
        "      self.model.train()\n",
        "      self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
        "      self.criterion = nn.CrossEntropyLoss()\n",
        "      total_correct = 0\n",
        "      total_samples = 0\n",
        "\n",
        "      for batch_idx, (inputs, labels) in enumerate(self.train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "          inputs = inputs.to(\"cuda:0\")\n",
        "          labels = labels.to(\"cuda:0\")\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: 1 [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "             batch_idx * len(inputs), len(self.train_loader.dataset),\n",
        "            100. * batch_idx / len(self.train_loader), loss.item()))\n",
        "          self.loss = loss.item()\n",
        "          torch.save(self.model.state_dict(), 'model.pth')\n",
        "          torch.save(self.optimizer.state_dict(), 'optimizer.pth')\n",
        "\n",
        "      train_accuracy = total_correct / total_samples\n",
        "      print ('Accuracy trainning: {}'.format(train_accuracy))\n",
        "      self.training_completed = True\n",
        "      self.next(self.local_model_validation)\n",
        "\n",
        "    @collaborator\n",
        "    def local_model_validation(self):\n",
        "        self.local_validation_score = inference(self.model,self.test_loader)\n",
        "        print(f'Doing local model validation for collaborator {self.input}: {self.local_validation_score}')\n",
        "        self.next(self.join, exclude=['training_completed'])\n",
        "\n",
        "    @aggregator\n",
        "    def join(self,inputs):\n",
        "        self.average_loss = sum(input.loss for input in inputs)/len(inputs)\n",
        "        self.aggregated_model_accuracy = sum(input.agg_validation_score for input in inputs)/len(inputs)\n",
        "        self.local_model_accuracy = sum(input.local_validation_score for input in inputs)/len(inputs)\n",
        "        print(f'Average aggregated model validation values = {self.aggregated_model_accuracy}')\n",
        "        print(f'Average training loss = {self.average_loss}')\n",
        "        print(f'Average local model validation values = {self.local_model_accuracy}')\n",
        "        self.model = FedAvg([input.model for input in inputs])\n",
        "        self.optimizer = [input.optimizer for input in inputs][0]\n",
        "        self.current_round += 1\n",
        "        if self.current_round < self.rounds:\n",
        "            self.next(self.aggregated_model_validation, foreach='collaborators', exclude=['private'])\n",
        "        else:\n",
        "            self.next(self.end)\n",
        "\n",
        "    @aggregator\n",
        "    def end(self):\n",
        "        print(f'This is the end of the flow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmohxazF4keT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbcce83-133f-4de3-93ba-b70268d6a36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local runtime collaborators = ['Portland', 'Seattle']\n"
          ]
        }
      ],
      "source": [
        "# Setup participants\n",
        "aggregator = Aggregator()\n",
        "aggregator.private_attributes = {}\n",
        "\n",
        "# Setup collaborators with private attributes\n",
        "collaborator_names = ['Portland', 'Seattle']\n",
        "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
        "for idx, collaborator in enumerate(collaborators):\n",
        "    local_train = deepcopy(train_dataset)\n",
        "    local_test = deepcopy(val_dataset)\n",
        "    indices_train = list(range(idx, len(train_dataset), len(collaborators)))\n",
        "    local_train = torch.utils.data.Subset(train_dataset, indices_train)\n",
        "    indices_val = list(range(idx, len(val_dataset), len(collaborators)))\n",
        "    local_test = torch.utils.data.Subset(val_dataset, indices_val)\n",
        "    collaborator.private_attributes = {\n",
        "            'train_loader': torch.utils.data.DataLoader(local_train,batch_size=batch_size_train, shuffle=True),\n",
        "            'test_loader': torch.utils.data.DataLoader(local_test,batch_size=batch_size_train, shuffle=True)\n",
        "    }\n",
        "\n",
        "local_runtime = LocalRuntime(aggregator=aggregator, collaborators=collaborators, backend='single_process')\n",
        "print(f'Local runtime collaborators = {local_runtime.collaborators}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIpsvZUN4w3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6170efaa-f8f2-4f7a-9cae-59dffedac04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating local datastore in current directory (/content/.metaflow)\n",
            "\n",
            "Calling start\n",
            "Performing initialization for model\n",
            "Sending state from aggregator to collaborators\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Performing aggregated model validation for collaborator Portland\n",
            "\n",
            "Test set: Avg. loss: -0.0001, Accuracy: 73/499 (14.63%)\n",
            "\n",
            "Portland value of 0.1462925851703407\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1163 (0%)]\tLoss: 1.599264\n",
            "Train Epoch: 1 [64/1163 (5%)]\tLoss: 421.417297\n",
            "Train Epoch: 1 [128/1163 (11%)]\tLoss: 97.920990\n",
            "Train Epoch: 1 [192/1163 (16%)]\tLoss: 23.086529\n",
            "Train Epoch: 1 [256/1163 (22%)]\tLoss: 20.206762\n",
            "Train Epoch: 1 [320/1163 (27%)]\tLoss: 6.614548\n",
            "Train Epoch: 1 [384/1163 (32%)]\tLoss: 2.648650\n",
            "Train Epoch: 1 [448/1163 (38%)]\tLoss: 2.771421\n",
            "Train Epoch: 1 [512/1163 (43%)]\tLoss: 1.928961\n",
            "Train Epoch: 1 [576/1163 (49%)]\tLoss: 2.442946\n",
            "Train Epoch: 1 [640/1163 (54%)]\tLoss: 1.438542\n",
            "Train Epoch: 1 [704/1163 (59%)]\tLoss: 1.090365\n",
            "Train Epoch: 1 [768/1163 (65%)]\tLoss: 1.411949\n",
            "Train Epoch: 1 [832/1163 (70%)]\tLoss: 1.120382\n",
            "Train Epoch: 1 [896/1163 (76%)]\tLoss: 1.483541\n",
            "Train Epoch: 1 [960/1163 (81%)]\tLoss: 1.117000\n",
            "Train Epoch: 1 [1024/1163 (86%)]\tLoss: 0.969388\n",
            "Train Epoch: 1 [1088/1163 (92%)]\tLoss: 1.506463\n",
            "Train Epoch: 1 [396/1163 (97%)]\tLoss: 1.091747\n",
            "Accuracy trainning: 0.411006018916595\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: Avg. loss: -0.4709, Accuracy: 335/499 (67.13%)\n",
            "\n",
            "Doing local model validation for collaborator Portland: 0.6713426853707415\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Performing aggregated model validation for collaborator Seattle\n",
            "\n",
            "Test set: Avg. loss: -0.0001, Accuracy: 77/499 (15.43%)\n",
            "\n",
            "Seattle value of 0.15430861723446893\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1163 (0%)]\tLoss: 1.608275\n",
            "Train Epoch: 1 [64/1163 (5%)]\tLoss: 430.596222\n",
            "Train Epoch: 1 [128/1163 (11%)]\tLoss: 169.706253\n",
            "Train Epoch: 1 [192/1163 (16%)]\tLoss: 32.486523\n",
            "Train Epoch: 1 [256/1163 (22%)]\tLoss: 24.924335\n",
            "Train Epoch: 1 [320/1163 (27%)]\tLoss: 16.523806\n",
            "Train Epoch: 1 [384/1163 (32%)]\tLoss: 14.698146\n",
            "Train Epoch: 1 [448/1163 (38%)]\tLoss: 4.942008\n",
            "Train Epoch: 1 [512/1163 (43%)]\tLoss: 2.998385\n",
            "Train Epoch: 1 [576/1163 (49%)]\tLoss: 1.969653\n",
            "Train Epoch: 1 [640/1163 (54%)]\tLoss: 2.220476\n",
            "Train Epoch: 1 [704/1163 (59%)]\tLoss: 1.699767\n",
            "Train Epoch: 1 [768/1163 (65%)]\tLoss: 3.052622\n",
            "Train Epoch: 1 [832/1163 (70%)]\tLoss: 2.000496\n",
            "Train Epoch: 1 [896/1163 (76%)]\tLoss: 2.077215\n",
            "Train Epoch: 1 [960/1163 (81%)]\tLoss: 1.685328\n",
            "Train Epoch: 1 [1024/1163 (86%)]\tLoss: 1.231541\n",
            "Train Epoch: 1 [1088/1163 (92%)]\tLoss: 2.733226\n",
            "Train Epoch: 1 [396/1163 (97%)]\tLoss: 1.011834\n",
            "Accuracy trainning: 0.3482373172828891\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: Avg. loss: -0.3759, Accuracy: 289/499 (57.92%)\n",
            "\n",
            "Doing local model validation for collaborator Seattle: 0.5791583166332666\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling join\n",
            "Average aggregated model validation values = 0.1503006012024048\n",
            "Average training loss = 1.0517905354499817\n",
            "Average local model validation values = 0.625250501002004\n",
            "Sending state from aggregator to collaborators\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Performing aggregated model validation for collaborator Portland\n",
            "\n",
            "Test set: Avg. loss: -0.1214, Accuracy: 148/499 (29.66%)\n",
            "\n",
            "Portland value of 0.2965931863727455\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1163 (0%)]\tLoss: 1.454182\n",
            "Train Epoch: 1 [64/1163 (5%)]\tLoss: 1.350374\n",
            "Train Epoch: 1 [128/1163 (11%)]\tLoss: 1.424821\n",
            "Train Epoch: 1 [192/1163 (16%)]\tLoss: 1.518448\n",
            "Train Epoch: 1 [256/1163 (22%)]\tLoss: 1.005228\n",
            "Train Epoch: 1 [320/1163 (27%)]\tLoss: 1.430420\n",
            "Train Epoch: 1 [384/1163 (32%)]\tLoss: 1.756057\n",
            "Train Epoch: 1 [448/1163 (38%)]\tLoss: 1.828353\n",
            "Train Epoch: 1 [512/1163 (43%)]\tLoss: 1.011436\n",
            "Train Epoch: 1 [576/1163 (49%)]\tLoss: 1.083416\n",
            "Train Epoch: 1 [640/1163 (54%)]\tLoss: 1.051800\n",
            "Train Epoch: 1 [704/1163 (59%)]\tLoss: 0.942493\n",
            "Train Epoch: 1 [768/1163 (65%)]\tLoss: 0.518831\n",
            "Train Epoch: 1 [832/1163 (70%)]\tLoss: 1.036919\n",
            "Train Epoch: 1 [896/1163 (76%)]\tLoss: 0.797201\n",
            "Train Epoch: 1 [960/1163 (81%)]\tLoss: 0.762685\n",
            "Train Epoch: 1 [1024/1163 (86%)]\tLoss: 1.268825\n",
            "Train Epoch: 1 [1088/1163 (92%)]\tLoss: 0.389901\n",
            "Train Epoch: 1 [396/1163 (97%)]\tLoss: 0.674135\n",
            "Accuracy trainning: 0.6096302665520207\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: Avg. loss: -1.0856, Accuracy: 368/499 (73.75%)\n",
            "\n",
            "Doing local model validation for collaborator Portland: 0.7374749498997996\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Performing aggregated model validation for collaborator Seattle\n",
            "\n",
            "Test set: Avg. loss: -0.1683, Accuracy: 161/499 (32.26%)\n",
            "\n",
            "Seattle value of 0.3226452905811623\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1163 (0%)]\tLoss: 1.520887\n",
            "Train Epoch: 1 [64/1163 (5%)]\tLoss: 1.408310\n",
            "Train Epoch: 1 [128/1163 (11%)]\tLoss: 1.174809\n",
            "Train Epoch: 1 [192/1163 (16%)]\tLoss: 1.642534\n",
            "Train Epoch: 1 [256/1163 (22%)]\tLoss: 1.032593\n",
            "Train Epoch: 1 [320/1163 (27%)]\tLoss: 1.307033\n",
            "Train Epoch: 1 [384/1163 (32%)]\tLoss: 2.106886\n",
            "Train Epoch: 1 [448/1163 (38%)]\tLoss: 1.062297\n",
            "Train Epoch: 1 [512/1163 (43%)]\tLoss: 1.366961\n",
            "Train Epoch: 1 [576/1163 (49%)]\tLoss: 0.992156\n",
            "Train Epoch: 1 [640/1163 (54%)]\tLoss: 0.876546\n",
            "Train Epoch: 1 [704/1163 (59%)]\tLoss: 0.976987\n",
            "Train Epoch: 1 [768/1163 (65%)]\tLoss: 1.075170\n",
            "Train Epoch: 1 [832/1163 (70%)]\tLoss: 0.756512\n",
            "Train Epoch: 1 [896/1163 (76%)]\tLoss: 1.325591\n",
            "Train Epoch: 1 [960/1163 (81%)]\tLoss: 1.014523\n",
            "Train Epoch: 1 [1024/1163 (86%)]\tLoss: 1.704509\n",
            "Train Epoch: 1 [1088/1163 (92%)]\tLoss: 1.014204\n",
            "Train Epoch: 1 [396/1163 (97%)]\tLoss: 1.489788\n",
            "Accuracy trainning: 0.5674978503869303\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: Avg. loss: -0.6771, Accuracy: 330/499 (66.13%)\n",
            "\n",
            "Doing local model validation for collaborator Seattle: 0.6613226452905812\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling join\n",
            "Average aggregated model validation values = 0.30961923847695394\n",
            "Average training loss = 1.0819610953330994\n",
            "Average local model validation values = 0.6993987975951903\n",
            "Sending state from aggregator to collaborators\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Performing aggregated model validation for collaborator Portland\n",
            "\n",
            "Test set: Avg. loss: -0.5830, Accuracy: 309/499 (61.92%)\n",
            "\n",
            "Portland value of 0.6192384769539078\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1163 (0%)]\tLoss: 1.264362\n",
            "Train Epoch: 1 [64/1163 (5%)]\tLoss: 1.181902\n",
            "Train Epoch: 1 [128/1163 (11%)]\tLoss: 2.101472\n",
            "Train Epoch: 1 [192/1163 (16%)]\tLoss: 0.591824\n",
            "Train Epoch: 1 [256/1163 (22%)]\tLoss: 0.596774\n",
            "Train Epoch: 1 [320/1163 (27%)]\tLoss: 0.304823\n",
            "Train Epoch: 1 [384/1163 (32%)]\tLoss: 0.916770\n",
            "Train Epoch: 1 [448/1163 (38%)]\tLoss: 0.566907\n",
            "Train Epoch: 1 [512/1163 (43%)]\tLoss: 1.463113\n",
            "Train Epoch: 1 [576/1163 (49%)]\tLoss: 0.834828\n",
            "Train Epoch: 1 [640/1163 (54%)]\tLoss: 4.081815\n",
            "Train Epoch: 1 [704/1163 (59%)]\tLoss: 0.672308\n",
            "Train Epoch: 1 [768/1163 (65%)]\tLoss: 0.499037\n",
            "Train Epoch: 1 [832/1163 (70%)]\tLoss: 0.822544\n",
            "Train Epoch: 1 [896/1163 (76%)]\tLoss: 1.637558\n",
            "Train Epoch: 1 [960/1163 (81%)]\tLoss: 0.981022\n",
            "Train Epoch: 1 [1024/1163 (86%)]\tLoss: 1.290893\n",
            "Train Epoch: 1 [1088/1163 (92%)]\tLoss: 0.618472\n",
            "Train Epoch: 1 [396/1163 (97%)]\tLoss: 0.635017\n",
            "Accuracy trainning: 0.7265692175408427\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: Avg. loss: -0.4017, Accuracy: 328/499 (65.73%)\n",
            "\n",
            "Doing local model validation for collaborator Portland: 0.657314629258517\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling aggregated_model_validation\n",
            "Performing aggregated model validation for collaborator Seattle\n",
            "\n",
            "Test set: Avg. loss: -0.7549, Accuracy: 300/499 (60.12%)\n",
            "\n",
            "Seattle value of 0.6012024048096193\n",
            "\n",
            "Calling train\n",
            "Train Epoch: 1 [0/1163 (0%)]\tLoss: 0.914669\n",
            "Train Epoch: 1 [64/1163 (5%)]\tLoss: 0.872578\n",
            "Train Epoch: 1 [128/1163 (11%)]\tLoss: 0.914347\n",
            "Train Epoch: 1 [192/1163 (16%)]\tLoss: 3.143565\n",
            "Train Epoch: 1 [256/1163 (22%)]\tLoss: 0.992680\n",
            "Train Epoch: 1 [320/1163 (27%)]\tLoss: 1.192787\n",
            "Train Epoch: 1 [384/1163 (32%)]\tLoss: 1.348179\n",
            "Train Epoch: 1 [448/1163 (38%)]\tLoss: 0.416904\n",
            "Train Epoch: 1 [512/1163 (43%)]\tLoss: 1.827536\n",
            "Train Epoch: 1 [576/1163 (49%)]\tLoss: 0.650913\n",
            "Train Epoch: 1 [640/1163 (54%)]\tLoss: 1.134807\n",
            "Train Epoch: 1 [704/1163 (59%)]\tLoss: 0.339172\n",
            "Train Epoch: 1 [768/1163 (65%)]\tLoss: 0.654397\n",
            "Train Epoch: 1 [832/1163 (70%)]\tLoss: 0.551476\n",
            "Train Epoch: 1 [896/1163 (76%)]\tLoss: 1.803607\n",
            "Train Epoch: 1 [960/1163 (81%)]\tLoss: 0.985892\n",
            "Train Epoch: 1 [1024/1163 (86%)]\tLoss: 0.860615\n",
            "Train Epoch: 1 [1088/1163 (92%)]\tLoss: 1.326447\n",
            "Train Epoch: 1 [396/1163 (97%)]\tLoss: 0.997063\n",
            "Accuracy trainning: 0.7265692175408427\n",
            "\n",
            "Calling local_model_validation\n",
            "\n",
            "Test set: Avg. loss: -0.2768, Accuracy: 359/499 (71.94%)\n",
            "\n",
            "Doing local model validation for collaborator Seattle: 0.7194388777555111\n",
            "Should transfer from local_model_validation to join\n",
            "\n",
            "Calling join\n",
            "Average aggregated model validation values = 0.6102204408817635\n",
            "Average training loss = 0.8160398602485657\n",
            "Average local model validation values = 0.688376753507014\n",
            "\n",
            "Calling end\n",
            "This is the end of the flow\n"
          ]
        }
      ],
      "source": [
        "model = None\n",
        "best_model = None\n",
        "optimizer = None\n",
        "criterion = None\n",
        "flflow = FederatedFlow(model,optimizer)\n",
        "flflow.runtime = local_runtime\n",
        "flflow.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF-6EbdH4xma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddba424-77c4-430d-9173-3d5343684e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of the final model weights: tensor([[[ 1.0152e-01, -6.0065e-02,  9.1386e-02,  2.6104e-02, -5.5867e-02],\n",
            "         [-2.0925e-02, -2.9945e-03,  9.9730e-03,  1.0478e-01,  1.1841e-01],\n",
            "         [ 9.1765e-02, -6.8904e-02, -3.2087e-02,  6.9336e-02,  1.2650e-04],\n",
            "         [-4.4866e-02,  7.9381e-02, -5.0584e-02, -3.3520e-02, -4.6605e-02],\n",
            "         [-3.4433e-02,  4.0261e-03,  1.1540e-02, -4.8760e-02,  8.3956e-02]],\n",
            "\n",
            "        [[ 3.0238e-01,  1.7149e-01,  2.7495e-01,  3.2557e-01,  2.3936e-01],\n",
            "         [ 1.4912e-01,  2.4339e-01,  1.1730e-01,  2.4477e-01,  2.0551e-01],\n",
            "         [ 1.5003e-01,  2.2926e-01,  1.5484e-01,  2.9847e-01,  2.4506e-01],\n",
            "         [ 2.4677e-01,  1.0762e-01,  1.9120e-01,  2.0563e-01,  2.1524e-01],\n",
            "         [ 1.4816e-01,  3.6062e-01,  1.8258e-01,  2.4615e-01,  1.0399e-01]],\n",
            "\n",
            "        [[-3.5534e-03,  1.3340e-03,  3.0253e-02,  1.0872e-01,  1.1768e-01],\n",
            "         [ 8.0828e-02,  9.7216e-02,  6.9078e-02,  1.1640e-01,  7.5406e-02],\n",
            "         [-2.5519e-02,  1.1671e-01,  6.7137e-04,  3.7655e-02,  9.1161e-02],\n",
            "         [ 6.1432e-04,  2.9824e-02,  1.7707e-02,  1.1197e-01,  7.8606e-02],\n",
            "         [ 5.0257e-02,  1.1206e-01, -8.8523e-03,  1.2744e-01,  1.9823e-02]]])\n",
            "\n",
            "Final aggregated model accuracy for 3 rounds of training: 0.6102204408817635\n"
          ]
        }
      ],
      "source": [
        "print(f'Sample of the final model weights: {flflow.model.state_dict()[\"conv1.weight\"][0]}')\n",
        "\n",
        "print(f'\\nFinal aggregated model accuracy for {flflow.rounds} rounds of training: {flflow.aggregated_model_accuracy}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}